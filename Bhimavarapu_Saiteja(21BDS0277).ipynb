{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Teja220/Tata-Communications-Cifar-Image-Classification/blob/main/Bhimavarapu_Saiteja(21BDS0277).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAH9BJC9ey8z",
        "outputId": "dc1ac8d5-f536-444f-9c71-0eacf078eebc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.25.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.10.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.20.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "V3tu2gcNhTPQ",
        "outputId": "af4bd8ea-8f02-4b10-bf15-2f163e402580"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msaitejaredyy\u001b[0m (\u001b[33msaitejaredyy-vellore-institute-of-technology\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "l6nhdVM-jxdi",
        "outputId": "47ec791e-6387-4d41-c49d-0e5bbe3d2669"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250201_095711-st0fwtr1</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification/runs/st0fwtr1' target=\"_blank\">pretty-pyramid-16</a></strong> to <a href='https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification' target=\"_blank\">https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification/runs/st0fwtr1' target=\"_blank\">https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification/runs/st0fwtr1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification/runs/st0fwtr1?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x78273ed5a350>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.init(project=\"cifar10-image-classification\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_GgT6Xgh3nI",
        "outputId": "dd9b827b-2448-48dd-b823-68eed13f9cf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:01<00:00, 104MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Data augmentation and normalization for training\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Download CIFAR-10 dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "valloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We will count the number of training images and test images, this is essential to understand the dataset\n",
        "num_train_images = len(trainset)\n",
        "num_test_images = len(testset)\n",
        "total_images = num_train_images + num_test_images\n",
        "\n",
        "print(f\"Number of training images: {num_train_images}\")\n",
        "print(f\"Number of test images: {num_test_images}\")\n",
        "print(f\"Total number of images: {total_images}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCfHWkNS8IHW",
        "outputId": "51f957c7-510b-4a59-e72f-dd6476caffaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training images: 50000\n",
            "Number of test images: 10000\n",
            "Total number of images: 60000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Further after checking the data set we will see if there are any corrupted samples there in the dataset or not, it's the basic step we need to do in any ML process to find the outliers in dataset\n",
        "def check_dataset(dataset):\n",
        "    corrupted = 0\n",
        "    for i in range(len(dataset)):\n",
        "        try:\n",
        "            image, label = dataset[i]\n",
        "        except Exception as e:\n",
        "            print(f\"Error in sample {i}: {e}\")\n",
        "            corrupted += 1\n",
        "    if corrupted == 0:\n",
        "        print(\"No corrupted samples found!\")\n",
        "    else:\n",
        "        print(f\"Found {corrupted} corrupted samples.\")\n",
        "\n",
        "check_dataset(trainset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncaG-4oQ8e7v",
        "outputId": "bb395a67-7c3a-4b2b-e85a-27ebde0747bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No corrupted samples found!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. First, we defined a simple CNN architecture to know how the model is performing and then we can fine tune it further in the notebook\n",
        "2. Two convolutional layers for feature extraction\n",
        "3. Max-pooling for dimensionality reduction\n",
        "4. Fully connected layers for classification\n",
        "5. ReLU activation for non-linearity"
      ],
      "metadata": {
        "id": "MWtsWESYKnnl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxWR88XMiwsJ"
      },
      "outputs": [],
      "source": [
        "from torch import nn, optim\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 8 * 8)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleCNN()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Cross-Entropy Loss is commonly used for multi-class classification problems.   \n",
        "2. Adam is an adaptive learning rate optimization algorithm.\n",
        "3. lr is the learning rate, lr=0.001 is the default lr for adam optimizer\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oYnJPT85LDIF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfjuG2PXjATF"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhfFK1XrjCkB",
        "outputId": "da667576-ced5-4672-a143-133abd176f3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.9590, Accuracy: 0.6615\n",
            "Epoch 2, Loss: 0.8038, Accuracy: 0.7189\n",
            "Epoch 3, Loss: 0.6876, Accuracy: 0.7582\n",
            "Epoch 4, Loss: 0.5814, Accuracy: 0.7970\n",
            "Epoch 5, Loss: 0.4856, Accuracy: 0.8286\n"
          ]
        }
      ],
      "source": [
        "# Defining the function to train the required number of epochs\n",
        "def train_model(epochs=5):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        total_correct = 0\n",
        "\n",
        "        for inputs, labels in trainloader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Help's us to Calculate metrics\n",
        "        epoch_loss = running_loss / len(trainloader)\n",
        "        epoch_accuracy = total_correct / len(trainset)\n",
        "\n",
        "        # Log metrics to W&B\n",
        "        wandb.log({\n",
        "            'Epoch': epoch + 1,\n",
        "            'Training Loss': epoch_loss,\n",
        "            'Training Accuracy': epoch_accuracy\n",
        "        })\n",
        "\n",
        "        print(f'Epoch {epoch + 1}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n",
        "\n",
        "# Recall the function to start training\n",
        "train_model(epochs=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "G2P_Fmz7ETsu",
        "outputId": "114f78ca-dbac-4176-ade1-f141241548b9"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msaitejaredyy\u001b[0m (\u001b[33msaitejaredyy-vellore-institute-of-technology\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hyper parameter Tuning - 1\n",
        "\n",
        "* Since we got the initial accuracy of 0.82 further by fine tuning we should be\n",
        "to achieve 90 or 95.\n",
        "* Hyper parameter Tuning - 1, key changes:\n",
        "\n",
        "1. Optimizer: SGD\n",
        "2. Learning rate: 0.01\n",
        "3. Batch size: 64\n",
        "\n"
      ],
      "metadata": {
        "id": "EOHP8GOANJrF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "id": "UntGZWlApZNW",
        "outputId": "52d827d0-1a2f-431c-ab2b-39f7602c22e8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250131_145521-mtilav6p</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification/runs/mtilav6p' target=\"_blank\">Hyperparameter Tuning 1</a></strong> to <a href='https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification' target=\"_blank\">https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification/runs/mtilav6p' target=\"_blank\">https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification/runs/mtilav6p</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 43.2MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Epoch 1, Loss: 2.0680, Accuracy: 0.2695\n",
            "Epoch 2, Loss: 1.6774, Accuracy: 0.4062\n",
            "Epoch 3, Loss: 1.4857, Accuracy: 0.4702\n",
            "Epoch 4, Loss: 1.3794, Accuracy: 0.5057\n",
            "Epoch 5, Loss: 1.2906, Accuracy: 0.5397\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▃▅▆█</td></tr><tr><td>Training Accuracy</td><td>▁▅▆▇█</td></tr><tr><td>Training Loss</td><td>█▄▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>5</td></tr><tr><td>Training Accuracy</td><td>0.53974</td></tr><tr><td>Training Loss</td><td>1.29065</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Hyperparameter Tuning 1</strong> at: <a href='https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification/runs/mtilav6p' target=\"_blank\">https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification/runs/mtilav6p</a><br> View project at: <a href='https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification' target=\"_blank\">https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250131_145521-mtilav6p/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch import nn, optim\n",
        "import wandb\n",
        "\n",
        "# Initialize W&B properly with the correct run name\n",
        "wandb.init(project=\"cifar10-image-classification\", name=\"Hyperparameter Tuning 1\", reinit=True)\n",
        "\n",
        "# Load CIFAR-10 dataset with batch size = 64\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "valloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Define the model\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 8 * 8)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initializing model, criterion, and optimizer\n",
        "model = SimpleCNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training loop with W&B logging\n",
        "def train_model(epochs=5):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        total_correct = 0\n",
        "\n",
        "        for inputs, labels in trainloader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Calculate metrics\n",
        "        epoch_loss = running_loss / len(trainloader)\n",
        "        epoch_accuracy = total_correct / len(trainset)\n",
        "\n",
        "        # Log metrics to W&B\n",
        "        wandb.log({\n",
        "            'Epoch': epoch + 1,\n",
        "            'Training Loss': epoch_loss,\n",
        "            'Training Accuracy': epoch_accuracy\n",
        "        })\n",
        "\n",
        "        print(f'Epoch {epoch + 1}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n",
        "\n",
        "    # Properly close this W&B run\n",
        "    wandb.finish()\n",
        "\n",
        "# Start training for Hyperparameter Tuning 1\n",
        "train_model(epochs=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hyperparameter Tuning - 2\n",
        "\n",
        "* After seeing the results by changing the optimizer from ADAM to SGD, the accuracy dropped drastically\n",
        "\n",
        "* We can consider ruling out the SGD optimizer\n",
        "\n",
        "* For the next run we will implement the following changes:\n",
        "\n",
        "1. Optimizer: Adam\n",
        "2. Learning rate: 0.001\n",
        "3. Batch size: 128"
      ],
      "metadata": {
        "id": "BjrAFYuLN-vk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "qzb_JuC_DRdK",
        "outputId": "a2075681-5ffd-444c-ab3e-79a078a180fb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250131_150413-u15zv18w</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification/runs/u15zv18w' target=\"_blank\">Hyperparameter Tuning 2</a></strong> to <a href='https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification' target=\"_blank\">https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification/runs/u15zv18w' target=\"_blank\">https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification/runs/u15zv18w</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch 1, Loss: 1.4217, Accuracy: 0.4878\n",
            "Epoch 2, Loss: 1.0472, Accuracy: 0.6329\n",
            "Epoch 3, Loss: 0.8809, Accuracy: 0.6930\n",
            "Epoch 4, Loss: 0.7738, Accuracy: 0.7292\n",
            "Epoch 5, Loss: 0.6818, Accuracy: 0.7638\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▃▅▆█</td></tr><tr><td>Training Accuracy</td><td>▁▅▆▇█</td></tr><tr><td>Training Loss</td><td>█▄▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>5</td></tr><tr><td>Training Accuracy</td><td>0.76382</td></tr><tr><td>Training Loss</td><td>0.68177</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Hyperparameter Tuning 2</strong> at: <a href='https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification/runs/u15zv18w' target=\"_blank\">https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification/runs/u15zv18w</a><br> View project at: <a href='https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification' target=\"_blank\">https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250131_150413-u15zv18w/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch import nn, optim\n",
        "import wandb\n",
        "\n",
        "# Initialize W&B for Hyperparameter Tuning 2\n",
        "wandb.init(project=\"cifar10-image-classification\", name=\"Hyperparameter Tuning 2\", reinit=True)\n",
        "\n",
        "# Load CIFAR-10 dataset with batch size = 128\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "valloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False)\n",
        "\n",
        "# Define the model\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 8 * 8)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initializing model, criterion, and optimizer\n",
        "model = SimpleCNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop with W&B logging\n",
        "def train_model(epochs=5):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        total_correct = 0\n",
        "\n",
        "        for inputs, labels in trainloader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Calculate metrics\n",
        "        epoch_loss = running_loss / len(trainloader)\n",
        "        epoch_accuracy = total_correct / len(trainset)\n",
        "\n",
        "        # Log metrics to W&B\n",
        "        wandb.log({\n",
        "            'Epoch': epoch + 1,\n",
        "            'Training Loss': epoch_loss,\n",
        "            'Training Accuracy': epoch_accuracy\n",
        "        })\n",
        "\n",
        "        print(f'Epoch {epoch + 1}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n",
        "\n",
        "    # Properly close this W&B run\n",
        "    wandb.finish()\n",
        "\n",
        "# Start training for Hyperparameter Tuning 2\n",
        "train_model(epochs=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hyperparameter Tuning - 3\n",
        "\n",
        "* So after using the ADAM optimizer and improved batch size to 128, we have improved the accuracy from 0.54(approx) to ~0.77. Now we will make the folllowing changes:\n",
        "\n",
        "1. Optimizer: Adam\n",
        "2. Learning rate: 0.0005\n",
        "3. Batch size: 128\n",
        "\n",
        "We have just adjusted the learnning rate to 0.0005 from 0.001"
      ],
      "metadata": {
        "id": "cbIqu6V6YkqU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "2MS3NwQz5BmT",
        "outputId": "1a119c99-7919-4ae7-d2f6-b2dfef9f49b3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250131_154334-2k9taah7</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification/runs/2k9taah7' target=\"_blank\">Hyperparameter Tuning 3</a></strong> to <a href='https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification' target=\"_blank\">https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification/runs/2k9taah7' target=\"_blank\">https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification/runs/2k9taah7</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch 1, Loss: 1.5351, Accuracy: 0.4512\n",
            "Epoch 2, Loss: 1.2030, Accuracy: 0.5776\n",
            "Epoch 3, Loss: 1.0480, Accuracy: 0.6321\n",
            "Epoch 4, Loss: 0.9461, Accuracy: 0.6706\n",
            "Epoch 5, Loss: 0.8701, Accuracy: 0.6953\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▃▅▆█</td></tr><tr><td>Training Accuracy</td><td>▁▅▆▇█</td></tr><tr><td>Training Loss</td><td>█▅▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>5</td></tr><tr><td>Training Accuracy</td><td>0.69534</td></tr><tr><td>Training Loss</td><td>0.8701</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Hyperparameter Tuning 3</strong> at: <a href='https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification/runs/2k9taah7' target=\"_blank\">https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification/runs/2k9taah7</a><br> View project at: <a href='https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification' target=\"_blank\">https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250131_154334-2k9taah7/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch import nn, optim\n",
        "import wandb\n",
        "\n",
        "# Initialize W&B for Hyperparameter Tuning 3\n",
        "wandb.init(project=\"cifar10-image-classification\", name=\"Hyperparameter Tuning 3\", reinit=True)\n",
        "\n",
        "# Load CIFAR-10 dataset with batch size = 128\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "valloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False)\n",
        "\n",
        "# Define the model\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 8 * 8)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initializing model, criterion, and optimizer\n",
        "model = SimpleCNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
        "\n",
        "# Training loop with W&B logging\n",
        "def train_model(epochs=5):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        total_correct = 0\n",
        "\n",
        "        for inputs, labels in trainloader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Calculate metrics\n",
        "        epoch_loss = running_loss / len(trainloader)\n",
        "        epoch_accuracy = total_correct / len(trainset)\n",
        "\n",
        "        # Log metrics to W&B\n",
        "        wandb.log({\n",
        "            'Epoch': epoch + 1,\n",
        "            'Training Loss': epoch_loss,\n",
        "            'Training Accuracy': epoch_accuracy\n",
        "        })\n",
        "\n",
        "        print(f'Epoch {epoch + 1}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n",
        "\n",
        "    # Properly close this W&B run\n",
        "    wandb.finish()\n",
        "\n",
        "# Start training for Hyperparameter Tuning 3\n",
        "train_model(epochs=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hyperparameter Tuning - 4\n",
        "\n",
        "* Doing this we have gain lost the accuracy falling back to 0.69 from ~0.77, now we will increase the learning rate and the number of epochs:\n",
        "\n",
        "1. Optimizer: Adam\n",
        "2. Learning rate: 0.0008\n",
        "3. Batch size: 128\n",
        "4. Epochs: 10"
      ],
      "metadata": {
        "id": "lYt_H8q_Z3Qi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        },
        "id": "FXOAz3gRCB7w",
        "outputId": "3df54be7-05b2-4110-cd54-b15bcc3b6b27"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250131_155230-1sl0oo7q</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification/runs/1sl0oo7q' target=\"_blank\">Hyperparameter Tuning 4</a></strong> to <a href='https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification' target=\"_blank\">https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification/runs/1sl0oo7q' target=\"_blank\">https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification/runs/1sl0oo7q</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch 1, Loss: 1.4752, Accuracy: 0.4712\n",
            "Epoch 2, Loss: 1.1254, Accuracy: 0.6009\n",
            "Epoch 3, Loss: 0.9603, Accuracy: 0.6612\n",
            "Epoch 4, Loss: 0.8427, Accuracy: 0.7051\n",
            "Epoch 5, Loss: 0.7523, Accuracy: 0.7386\n",
            "Epoch 6, Loss: 0.6679, Accuracy: 0.7678\n",
            "Epoch 7, Loss: 0.5916, Accuracy: 0.7932\n",
            "Epoch 8, Loss: 0.5249, Accuracy: 0.8185\n",
            "Epoch 9, Loss: 0.4538, Accuracy: 0.8428\n",
            "Epoch 10, Loss: 0.3918, Accuracy: 0.8651\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Training Accuracy</td><td>▁▃▄▅▆▆▇▇██</td></tr><tr><td>Training Loss</td><td>█▆▅▄▃▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Training Accuracy</td><td>0.86506</td></tr><tr><td>Training Loss</td><td>0.39184</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Hyperparameter Tuning 4</strong> at: <a href='https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification/runs/1sl0oo7q' target=\"_blank\">https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification/runs/1sl0oo7q</a><br> View project at: <a href='https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification' target=\"_blank\">https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250131_155230-1sl0oo7q/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch import nn, optim\n",
        "import wandb\n",
        "\n",
        "# Initialize W&B for Hyperparameter Tuning 4\n",
        "wandb.init(project=\"cifar10-image-classification\", name=\"Hyperparameter Tuning 4\", reinit=True)\n",
        "\n",
        "# Load CIFAR-10 dataset with batch size = 128\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "valloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False)\n",
        "\n",
        "# Define the model\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 8 * 8)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initializing model, criterion, and optimizer\n",
        "model = SimpleCNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0008)\n",
        "\n",
        "# Training loop with W&B logging\n",
        "def train_model(epochs=10):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        total_correct = 0\n",
        "\n",
        "        for inputs, labels in trainloader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Calculate metrics\n",
        "        epoch_loss = running_loss / len(trainloader)\n",
        "        epoch_accuracy = total_correct / len(trainset)\n",
        "\n",
        "        # Log metrics to W&B\n",
        "        wandb.log({\n",
        "            'Epoch': epoch + 1,\n",
        "            'Training Loss': epoch_loss,\n",
        "            'Training Accuracy': epoch_accuracy\n",
        "        })\n",
        "\n",
        "        print(f'Epoch {epoch + 1}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n",
        "\n",
        "    # Properly close this W&B run\n",
        "    wandb.finish()\n",
        "\n",
        "# Start training for Hyperparameter Tuning 4\n",
        "train_model(epochs=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hyperparameter Tuning - 5\n",
        "\n",
        "* We got a good accuracy of 0.865 from the previous run 0.69, if we run 25 epochs we can easily reach 0.90 accuracy.\n",
        "\n",
        "* This experiment introduces model architecture improvements with:\n",
        "* Increased convolutional filters for better feature extraction.\n",
        "* Reduced dropout (p=0.1) for effective learning without overfitting.\n",
        "\n",
        "* We have implemented, the following:\n",
        "\n",
        "1. Increased filters: 32 → 64, 64 → 128\n",
        "2. Dropout: p=0.1\n",
        "3. Learning rate: 0.0008\n",
        "4. Batch size: 128\n",
        "5. Epochs: 10\n"
      ],
      "metadata": {
        "id": "Jn9tPK4XbIGf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        },
        "id": "loWi0RLaEEvX",
        "outputId": "0426635e-4cb6-45a3-a088-180447b45e3a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250131_164618-ill64v4x</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification/runs/ill64v4x' target=\"_blank\">Hyperparameter Tuning 5</a></strong> to <a href='https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification' target=\"_blank\">https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification/runs/ill64v4x' target=\"_blank\">https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification/runs/ill64v4x</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch 1, Loss: 1.3490, Accuracy: 0.5162\n",
            "Epoch 2, Loss: 0.9617, Accuracy: 0.6604\n",
            "Epoch 3, Loss: 0.7912, Accuracy: 0.7223\n",
            "Epoch 4, Loss: 0.6595, Accuracy: 0.7685\n",
            "Epoch 5, Loss: 0.5357, Accuracy: 0.8124\n",
            "Epoch 6, Loss: 0.4238, Accuracy: 0.8527\n",
            "Epoch 7, Loss: 0.3227, Accuracy: 0.8878\n",
            "Epoch 8, Loss: 0.2315, Accuracy: 0.9204\n",
            "Epoch 9, Loss: 0.1702, Accuracy: 0.9433\n",
            "Epoch 10, Loss: 0.1317, Accuracy: 0.9564\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Training Accuracy</td><td>▁▃▄▅▆▆▇▇██</td></tr><tr><td>Training Loss</td><td>█▆▅▄▃▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Training Accuracy</td><td>0.95638</td></tr><tr><td>Training Loss</td><td>0.13169</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Hyperparameter Tuning 5</strong> at: <a href='https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification/runs/ill64v4x' target=\"_blank\">https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification/runs/ill64v4x</a><br> View project at: <a href='https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification' target=\"_blank\">https://wandb.ai/saitejaredyy-vellore-institute-of-technology/cifar10-image-classification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250131_164618-ill64v4x/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch import nn, optim\n",
        "import wandb\n",
        "\n",
        "# Initialize W&B for Hyperparameter Tuning 6\n",
        "wandb.init(project=\"cifar10-image-classification\", name=\"Hyperparameter Tuning 5\", reinit=True)\n",
        "\n",
        "# Load CIFAR-10 dataset with batch size = 128\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "valloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False)\n",
        "\n",
        "# Define the model with more filters and reduced dropout\n",
        "class EnhancedCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EnhancedCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)  # Increased filters\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)  # Increased filters\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout = nn.Dropout(p=0.1)  # Reduced dropout\n",
        "        self.fc1 = nn.Linear(128 * 8 * 8, 256)  # Increased layer size\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 128 * 8 * 8)\n",
        "        x = self.dropout(self.relu(self.fc1(x)))  # Apply dropout\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initializing model, criterion, and optimizer\n",
        "model = EnhancedCNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0008)\n",
        "\n",
        "# Training loop with W&B logging\n",
        "def train_model(epochs=10):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        total_correct = 0\n",
        "\n",
        "        for inputs, labels in trainloader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Calculate metrics\n",
        "        epoch_loss = running_loss / len(trainloader)\n",
        "        epoch_accuracy = total_correct / len(trainset)\n",
        "\n",
        "        # Log metrics to W&B\n",
        "        wandb.log({\n",
        "            'Epoch': epoch + 1,\n",
        "            'Training Loss': epoch_loss,\n",
        "            'Training Accuracy': epoch_accuracy\n",
        "        })\n",
        "\n",
        "        print(f'Epoch {epoch + 1}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n",
        "\n",
        "    # Properly close this W&B run\n",
        "    wandb.finish()\n",
        "\n",
        "# Start training for Hyperparameter Tuning 6\n",
        "train_model(epochs=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Key Findings:\n",
        "\n",
        "1. Adam's adaptive learning technique beat SGD, particularly at modest learning rates.\n",
        "2. Lowering the learning rate too much negatively impacted performance, while balancing it (~0.0008) improved accuracy.\n",
        "3. Batch size: A batch size of 128 achieved a decent blend of gradient stability and speedier convergence.\n",
        "4. Enhanced architecture: Increasing convolutional filters and decreasing dropout resulted in much higher accuracy, demonstrating the importance of model capacity for feature extraction."
      ],
      "metadata": {
        "id": "Ry9_svUTc18U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Best Configuration:\n",
        "\n",
        "1. Optimizer: Adam\n",
        "2. Learning rate: 0.0008\n",
        "3. Batch size: 128\n",
        "4. Dropout: 0.1\n",
        "5. Epochs: 10\n",
        "6. Enhanced convolutional filters (64 → 128)\n",
        "\n",
        "* This configuration produced 95.64% accuracy, demonstrating the necessity of incremental tuning and architectural enhancements for peak performance."
      ],
      "metadata": {
        "id": "f_G6yuWCfSQO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lVL2uKI4f9TO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqVTyIWt75ezC/yPPmJ59U",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}